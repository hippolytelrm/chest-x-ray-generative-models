{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8763ef72",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a22b49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from src.models.denoising_diffusion import GaussianDiffusion\n",
    "from src.models.unet import Unet\n",
    "from src.utils.files import load_omegaconf_from_yaml\n",
    "from src.config.settings import CONFIG_PATH, DATA_PATH\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915ae700",
   "metadata": {},
   "source": [
    "# Model loading \n",
    "\n",
    "In the following cell, we initiate the model and load the checkpoint weights. \\\n",
    "You have to adapt the model checkpoint path to your checkpoint location. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3766cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-A100 GPU detected, using math or mem efficient attention if input tensor is on cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "config = load_omegaconf_from_yaml(path=CONFIG_PATH)\n",
    "\n",
    "path_weights = \"./results/model-15.pt\" #adapt the path to your checkpoint location\n",
    "\n",
    "model = Unet(dim=config.ddpm.size, channels=config.ddpm.unet.channels, dim_mults=config.ddpm.unet.dim_mults)\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "diffusion = GaussianDiffusion(\n",
    "    model,\n",
    "    image_size=config.ddpm.size,\n",
    "    timesteps=config.ddpm.gaussian_diffusion.timesteps,\n",
    "    sampling_timesteps=config.ddpm.gaussian_diffusion.sampling_timesteps,\n",
    ")\n",
    "\n",
    "model_state_dict = torch.load(f=path_weights, map_location=device)\n",
    "diffusion.load_state_dict(model_state_dict[\"model\"])\n",
    "\n",
    "diffusion = diffusion.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052f500a",
   "metadata": {},
   "source": [
    "# Generating samples using checkpoint\n",
    "\n",
    "Let's generate chest X-ray samples using the pre-trained model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a71e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sampling loop time step:  58%|████████████████████████████████████████████████████████████████████▌                                                  | 144/250 [01:04<00:46,  2.30it/s]"
     ]
    }
   ],
   "source": [
    "sampled_images = diffusion.sample(batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348ca502",
   "metadata": {},
   "source": [
    "# Qualitative and visual results\n",
    "\n",
    "In the following cell, we visualize the samples generated by Denoising Diffusion Probabilistic Modeling. \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0c2419",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.helpers import tensor_to_numpy_image\n",
    "\n",
    "sampled_images_np = sampled_images.detach().cpu().numpy().transpose(0,2,3,1)\n",
    "\n",
    "for i, sample in enumerate(sampled_images_np):\n",
    "    plt.subplot(2,2,i+1)\n",
    "    plt.imshow(sample, cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kernel",
   "language": "python",
   "name": "kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
